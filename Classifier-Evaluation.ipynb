{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 322\n",
    "## Final Project\n",
    "### Classifier Tests and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset and classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data and classifiers \n",
    "\n",
    "my_dataset = MyPyTable().load_from_file(\"input_data/NFL_regseason_data_clean.csv\")\n",
    "\n",
    "X_data = []\n",
    "for row in my_dataset.data: # Creating X_data\n",
    "    new_row = []\n",
    "    new_row.append(row[my_dataset.column_names.index('WinPercentage')])\n",
    "    new_row.append(row[my_dataset.column_names.index('Scoring')])\n",
    "    new_row.append(row[my_dataset.column_names.index('DefenseScoringAllowed')])\n",
    "    new_row.append(row[my_dataset.column_names.index('KickingPercentage')])\n",
    "    new_row.append(row[my_dataset.column_names.index('TurnoverMargin')])\n",
    "\n",
    "    X_data.append(new_row)\n",
    "\n",
    "y_data = my_dataset.get_column('Winner') #Creating y_data\n",
    "\n",
    "NFL_Bayes_Classifier = MyNaiveBayesClassifier()\n",
    "NFL_Knn_Classifier = MyKNeighborsClassifier()\n",
    "NFL_Tree_Classifier = MyDecisionTreeClassifier()\n",
    "# TODO: Implement random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using K-fold Cross Validation on Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds = myevaluation.kfold_split(X_data, 10)\n",
    "y_folds = myevaluation.kfold_split(y_data, 10)\n",
    "total_knn_accuracy, total_bayes_accuracy, total_tree_accuracy = 0, 0, 0\n",
    "knn_precision, bayes_precision, tree_precision = 0, 0, 0\n",
    "knn_recall, bayes_recall, tree_recall = 0, 0, 0\n",
    "knn_F1, bayes_F1, tree_F1 = 0, 0, 0\n",
    "knn_predictions, bayes_predictions, tree_predictions = [], [], []\n",
    "\n",
    "\n",
    "for i in range(len(X_folds)): # loop for kfold cross validation (through all three classifiers)\n",
    "    X_train, X_test, y_train, y_test = myutils.create_data(X_folds[i], y_folds[i], X_data, y_data)\n",
    "    NFL_Bayes_Classifier.fit(X_train, y_train)\n",
    "    NFL_Knn_Classifier.fit(X_train, y_train, type=\"discrete\")\n",
    "    NFL_Tree_Classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_knn_pred = NFL_Knn_Classifier.predict(X_test)\n",
    "    y_bayes_pred = NFL_Bayes_Classifier.predict(X_test)\n",
    "    y_tree_pred = NFL_Tree_Classifier.predict(X_test)\n",
    "\n",
    "    # Accuracy Calculations\n",
    "    total_knn_accuracy += myevaluation.accuracy_score(y_knn_pred, y_test) / 10\n",
    "    total_bayes_accuracy += myevaluation.accuracy_score(y_bayes_pred, y_test) / 10\n",
    "    total_tree_accuracy += myevaluation.accuracy_score(y_tree_pred, y_test) / 10\n",
    "\n",
    "    # Precision Calculations\n",
    "    knn_precision += myevaluation.binary_precision_score(y_knn_pred, y_test, pos_label=\"H\") / 10\n",
    "    bayes_precision += myevaluation.binary_precision_score(y_bayes_pred, y_test, pos_label=\"H\") / 10\n",
    "    tree_precision += myevaluation.binary_precision_score(y_tree_pred, y_test, pos_label=\"H\") / 10\n",
    "\n",
    "    # Recall Calculations \n",
    "    knn_recall += myevaluation.binary_recall_score(y_knn_pred, y_test, pos_label=\"H\") / 10\n",
    "    bayes_recall += myevaluation.binary_recall_score(y_bayes_pred, y_test, pos_label=\"H\") / 10\n",
    "    tree_recall += myevaluation.binary_recall_score(y_tree_pred, y_test, pos_label=\"H\") / 10\n",
    "\n",
    "    # F1 Calculations\n",
    "    knn_F1 += myevaluation.binary_f1_score(y_knn_pred, y_test, pos_label=\"H\") / 10\n",
    "    bayes_F1 += myevaluation.binary_f1_score(y_bayes_pred, y_test, pos_label=\"H\") / 10\n",
    "    tree_F1 += myevaluation.binary_f1_score(y_tree_pred, y_test, pos_label=\"H\") / 10\n",
    "\n",
    "    # Building Confusion Matrices\n",
    "    for prediction in y_knn_pred:\n",
    "        knn_predictions.append(prediction)\n",
    "    for prediction in y_bayes_pred:\n",
    "        bayes_predictions.append(prediction)\n",
    "    for prediction in y_tree_pred:\n",
    "        tree_predictions.append(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Knn Classifier -------\n",
      "Accuracy:  0.54 | Error Rate:  0.46\n",
      "Precision :  0.98 | Recall:  0.54 | F1 measure:  0.69\n",
      "Knn Confusion Matrix: \n",
      "+-------+------+----+-------+\n",
      "|       | H    | A  | total |\n",
      "+-------+------+----+-------+\n",
      "| H     | 934  | 15 | 949   |\n",
      "+-------+------+----+-------+\n",
      "| A     | 804  | 9  | 813   |\n",
      "+-------+------+----+-------+\n",
      "| total | 1738 | 24 | 1762  |\n",
      "+-------+------+----+-------+\n",
      "\n",
      "------- Bayes Classifier -------\n",
      "Accuracy:  0.6 | Error Rate:  0.4\n",
      "Precision :  0.69 | Recall:  0.61 | F1 measure:  0.65\n",
      "Bayes Confusion Matrix: \n",
      "+-------+------+-----+-------+\n",
      "|       | H    | A   | total |\n",
      "+-------+------+-----+-------+\n",
      "| H     | 653  | 296 | 949   |\n",
      "+-------+------+-----+-------+\n",
      "| A     | 414  | 399 | 813   |\n",
      "+-------+------+-----+-------+\n",
      "| total | 1067 | 695 | 1762  |\n",
      "+-------+------+-----+-------+\n",
      "\n",
      "------- Decision Tree Classifier -------\n",
      "Accuracy:  0.71 | Error Rate:  0.29\n",
      "Precision :  0.75 | Recall:  0.72 | F1 measure:  0.73\n",
      "Tree Confusion Matrix: \n",
      "+-------+-----+-----+-------+\n",
      "|       | H   | A   | total |\n",
      "+-------+-----+-----+-------+\n",
      "| H     | 710 | 239 | 949   |\n",
      "+-------+-----+-----+-------+\n",
      "| A     | 278 | 535 | 813   |\n",
      "+-------+-----+-----+-------+\n",
      "| total | 988 | 774 | 1762  |\n",
      "+-------+-----+-----+-------+\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Knn Classifier -------\")\n",
    "print(\"Accuracy: \", round(total_knn_accuracy, 2), \"| Error Rate: \", round(1 - total_knn_accuracy, 2))\n",
    "print(\"Precision : \", round(knn_precision, 2), \"| Recall: \", round(knn_recall, 2), \"| F1 measure: \", round(knn_F1, 2))\n",
    "print(\"Knn Confusion Matrix: \")\n",
    "myutils.print_matrix(myevaluation.confusion_matrix(y_data, knn_predictions, [\"H\", \"A\"]), [\"H\", \"A\"])\n",
    "print()\n",
    "print(\"------- Bayes Classifier -------\")\n",
    "print(\"Accuracy: \", round(total_bayes_accuracy, 2), \"| Error Rate: \", round(1 - total_bayes_accuracy, 2))\n",
    "print(\"Precision : \", round(bayes_precision, 2), \"| Recall: \", round(bayes_recall, 2), \"| F1 measure: \", round(bayes_F1, 2))\n",
    "print(\"Bayes Confusion Matrix: \")\n",
    "myutils.print_matrix(myevaluation.confusion_matrix(y_data, bayes_predictions, [\"H\", \"A\"]), [\"H\", \"A\"])\n",
    "print()\n",
    "print(\"------- Decision Tree Classifier -------\")\n",
    "print(\"Accuracy: \", round(total_tree_accuracy, 2), \"| Error Rate: \", round(1 - total_tree_accuracy, 2))\n",
    "print(\"Precision : \", round(tree_precision, 2), \"| Recall: \", round(tree_recall, 2), \"| F1 measure: \", round(tree_F1, 2))\n",
    "print(\"Tree Confusion Matrix: \")\n",
    "myutils.print_matrix(myevaluation.confusion_matrix(y_data, tree_predictions, [\"H\", \"A\"]), [\"H\", \"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF att1 == A AND att2 == A AND att4 == A AND att0 == A AND att3 == A THEN Winner == H\n",
      "IF att1 == A AND att2 == A AND att4 == A AND att0 == A AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == A AND att4 == A AND att0 == H AND att3 == A THEN Winner == A\n",
      "IF att1 == A AND att2 == A AND att4 == A AND att0 == H AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == A AND att4 == H AND att0 == A AND att3 == A THEN Winner == H\n",
      "IF att1 == A AND att2 == A AND att4 == H AND att0 == A AND att3 == H THEN Winner == H\n",
      "IF att1 == A AND att2 == A AND att4 == H AND att0 == H AND att3 == A THEN Winner == H\n",
      "IF att1 == A AND att2 == A AND att4 == H AND att0 == H AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == A AND att0 == A AND att3 == A THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == A AND att0 == A AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == A AND att0 == H AND att3 == A THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == A AND att0 == H AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == H AND att0 == A AND att3 == A THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == H AND att0 == A AND att3 == H THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == H AND att0 == H AND att3 == A THEN Winner == A\n",
      "IF att1 == A AND att2 == H AND att4 == H AND att0 == H AND att3 == H THEN Winner == A\n",
      "IF att1 == H AND att2 == A AND att4 == A AND att0 == A AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == A AND att0 == A AND att3 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == A AND att0 == H AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == A AND att0 == H AND att3 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == H AND att0 == A AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == H AND att0 == A AND att3 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == H AND att0 == H AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == A AND att4 == H AND att0 == H AND att3 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == A AND att3 == A AND att0 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == A AND att3 == A AND att0 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == A AND att3 == H AND att0 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == A AND att3 == H AND att0 == H THEN Winner == A\n",
      "IF att1 == H AND att2 == H AND att4 == H AND att0 == A AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == H AND att0 == A AND att3 == H THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == H AND att0 == H AND att3 == A THEN Winner == H\n",
      "IF att1 == H AND att2 == H AND att4 == H AND att0 == H AND att3 == H THEN Winner == H\n"
     ]
    }
   ],
   "source": [
    "NFL_Tree_Classifier.fit(X_train, y_train)\n",
    "NFL_Tree_Classifier.print_decision_rules(class_name=\"Winner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
